# LoggingUtils Directory

## Overview
The `LoggingUtils` directory is responsible for managing logging utilities for the project. It provides tools to handle logging operations, ensuring that all application events, errors, and debugging information are recorded consistently and efficiently. This directory plays a critical role in monitoring the application's behavior, debugging issues, and maintaining a record of operations for auditing purposes.

The logging utilities are designed to be flexible, thread-safe, and easy to integrate into various components of the project, such as the `Driver` class in the `ScraperUtils` module.

---

## Directory Structure
The `LoggingUtils` directory contains the following files and subdirectories:

---

## File Descriptions

### 1. `__init__.py`
- **Purpose**: Marks the `LoggingUtils` directory as a Python package, allowing its modules to be imported elsewhere in the project.
- **Details**: This file may include package-level imports or initialization logic.

---

### 2. `WebScrapeLogger.py`
- **Purpose**: Provides a singleton logger specifically designed for web scraping operations.
- **Key Features**:
  - Implements a thread-safe singleton pattern to ensure only one logger instance is created.
  - Configures logging levels (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL).
  - Logs messages to a file (`scraper-log.log`) and optionally to the console.
- **Use Case**: Used to log events and errors during web scraping tasks, such as page navigation, element interactions, and exceptions.

---

### 3. `RecordLogger.py`
- **Purpose**: Provides a logger for recording data-related operations, such as saving scraped data or processing records.
- **Key Features**:
  - Logs data processing events, such as successful saves or errors during data handling.
  - Can be configured to log to separate files for better organization.
- **Use Case**: Used to log operations related to data handling, such as saving records to a database or writing to files.

---

### 4. `__pycache__/`
- **Purpose**: Stores compiled Python files (`.pyc`) for performance optimization.
- **Details**: This directory is automatically generated by Python and does not require manual modification.

---

### 5. `docs/`
- **Purpose**: Contains documentation related to the `LoggingUtils` module.
- **Details**:
  - May include markdown files, diagrams, or other resources explaining how to use the logging utilities.
  - Helps developers understand the purpose and usage of the logging utilities.

---

## Deliverables
The `LoggingUtils` directory provides the following deliverables:
1. **Web Scraping Logger**: The `WebScrapeLogger.py` module provides a centralized logging utility for web scraping operations.
2. **Data Operation Logger**: The `RecordLogger.py` module provides a specialized logger for recording data-related events.
3. **Documentation**: The `docs/` folder provides resources to help developers understand and use the logging utilities effectively.

---

## Use Cases

### 1. **Logging Web Scraping Events**
- The `WebScrapeLogger` is used to log events during web scraping tasks, such as:
  - Navigating to a webpage.
  - Interacting with web elements.
  - Handling exceptions during scraping.
- Example:
  ```python
  from LoggingUtils.WebScrapeLogger import WebScrapeLogger

  WebScrapeLogger.info("Navigating to the target webpage.")
  WebScrapeLogger.error("Failed to locate the search button.")